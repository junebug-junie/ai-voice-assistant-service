# configuration for the PUBLIC PRODUCTION environment
# Caddy server configured for a public domain and Let's Encrypt

services:
  llm-brain:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    networks:
      - app-net

  voice-app:
    build: .
    volumes:
      - ./templates:/app/templates
    ports:
      - "8080"
    depends_on:
      - llm-brain
      - coqui-tts
    restart: unless-stopped
    environment:
      - LLM_URL=http://llm-brain:11434/api/chat
      - TTS_URL=http://coqui-tts:5002/api/tts
      - WHISPER_MODEL_SIZE=${WHISPER_MODEL_SIZE}
      - WHISPER_DEVICE=${WHISPER_DEVICE}
      - WHISPER_COMPUTE_TYPE=${WHISPER_COMPUTE_TYPE}
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia
    networks:
      - app-net

  coqui-tts:
    image: ghcr.io/coqui-ai/tts-cpu
    ports:
      - "5002"
    environment:
      - TTS_MODEL_NAME=tts_models/en/ljspeech/vits
    restart: unless-stopped
    entrypoint: tts-server
    networks:
      - app-net

  caddy:
    image: caddy:2-alpine
    restart: unless-stopped
    ports:
      - "80:80"     # standard public web ports
      - "443:443"
    volumes:
      - ./Caddyfile.prod:/etc/caddy/Caddyfile # Mount prod Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - voice-app
    networks:
      - app-net

volumes:
  ollama_data:
  caddy_data:
  caddy_config:

networks:
  app-net:
    driver: bridge
