<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice AI Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .pulse {
            animation: pulse-animation 1.5s infinite;
        }
        @keyframes pulse-animation {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
</head>
<body class="bg-black text-gray-200 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-2xl bg-gray-900 rounded-2xl shadow-lg p-6 md:p-8 space-y-6">
        <div class="text-center">
            <h1 class="text-3xl font-bold text-white">Voice AI Assistant</h1>
            <p id="status" class="text-gray-400 mt-2">Press and hold the button to speak</p>
        </div>

        <div class="flex justify-center items-center py-8">
            <button id="recordButton" class="bg-red-600 hover:bg-red-700 text-white rounded-full w-24 h-24 flex items-center justify-center transition-transform transform focus:outline-none focus:ring-4 focus:ring-red-500/50">
                <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" x2="12" y1="19" y2="22"></line></svg>
            </button>
        </div>

        <div id="conversation" class="space-y-4 max-h-96 overflow-y-auto p-4 bg-gray-800/50 rounded-lg">
            <!-- Conversation will be appended here -->
        </div>
    </div>

    <script>
        const recordButton = document.getElementById('recordButton');
        const statusDiv = document.getElementById('status');
        const conversationDiv = document.getElementById('conversation');
        let socket;
        let mediaRecorder;
        let audioChunks = [];
        
        // --- FIX: Add Text-to-Speech (TTS) function ---
        function speak(text) {
            // Cancel any previous speech to prevent overlap
            speechSynthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            // Optional: configure voice, rate, pitch
            // utterance.voice = speechSynthesis.getVoices()[0]; // Example: use the first available voice
            // utterance.rate = 1; // From 0.1 to 10
            // utterance.pitch = 1; // From 0 to 2
            
            speechSynthesis.speak(utterance);
        }

        function setupWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws`;
            console.log(`Attempting to connect to WebSocket at: ${wsUrl}`);
            
            socket = new WebSocket(wsUrl);

            socket.onopen = () => {
                console.log('WebSocket connection established.');
                statusDiv.textContent = 'Connection established. Hold button to speak.';
                recordButton.disabled = false;
            };

            socket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.transcript) {
                    appendMessage('You', data.transcript);
                } else if (data.llm_response) {
                    appendMessage('Assistant', data.llm_response);
                    // --- FIX: Speak the assistant's response ---
                    speak(data.llm_response); 
                } else if (data.error) {
                    const errorMessage = `Error: ${data.error}`;
                    statusDiv.textContent = errorMessage;
                    appendMessage('System', errorMessage, 'text-red-400');
                    speak(errorMessage); // Also speak the error
                }
            };

            socket.onclose = (event) => {
                console.error('WebSocket disconnected:', event.reason, `Code: ${event.code}`);
                statusDiv.textContent = 'Connection lost. Please refresh.';
                recordButton.disabled = true;
            };

            socket.onerror = (error) => {
                console.error('WebSocket error:', error);
                statusDiv.textContent = 'Connection error. Please refresh.';
                recordButton.disabled = true;
            };
        }

        function appendMessage(sender, text, colorClass = 'text-white') {
            const senderClass = sender === 'You' ? 'font-semibold text-blue-300' : 'font-semibold text-green-300';
            const messageElement = document.createElement('div');
            messageElement.innerHTML = `<p class="${senderClass}">${sender}</p><p class="${colorClass}">${text}</p>`;
            conversationDiv.appendChild(messageElement);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
        }
        
        async function startRecording() {
            // --- FIX: Stop any currently playing speech when starting to record ---
            speechSynthesis.cancel();
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    if (socket && socket.readyState === WebSocket.OPEN && audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
                        
                        const reader = new FileReader();
                        reader.readAsDataURL(audioBlob); 
                        reader.onloadend = function() {
                            const base64data = reader.result;                
                            const base64String = base64data.split(',')[1];
                            socket.send(base64String);
                        }
                    }
                    stream.getTracks().forEach(track => track.stop());
                };

                audioChunks = [];
                mediaRecorder.start();
                
                statusDiv.textContent = 'Recording... Release to stop.';
                recordButton.classList.add('pulse');

            } catch (err) {
                console.error('Error accessing microphone:', err);
                statusDiv.textContent = 'Error: Microphone access denied.';
                if (window.location.protocol !== 'https:') {
                    statusDiv.innerHTML += '<br>Microphone requires a secure (HTTPS) connection.';
                }
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                statusDiv.textContent = 'Processing...';
                recordButton.classList.remove('pulse');
            }
        }
        
        recordButton.addEventListener('mousedown', startRecording);
        recordButton.addEventListener('mouseup', stopRecording);
        recordButton.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording();
        });
        recordButton.addEventListener('touchend', stopRecording);

        window.addEventListener('load', setupWebSocket);
    </script>
</body>
</html>

