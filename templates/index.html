<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice AI Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .pulse { animation: pulse-animation 1.5s infinite; }
        @keyframes pulse-animation {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none; appearance: none;
            width: 20px; height: 20px;
            background: #EF4444; /* Red-500 */
            cursor: pointer; border-radius: 50%;
            margin-top: -6px;
        }
        input[type=range]::-moz-range-thumb {
            width: 20px; height: 20px;
            background: #EF4444; /* Red-500 */
            cursor: pointer; border-radius: 50%;
        }
    </style>
</head>
<body class="bg-black text-gray-200 flex items-center justify-center min-h-screen p-4 md:p-8">

    <div class="w-full max-w-7xl mx-auto flex flex-col md:flex-row gap-8">

        <!-- Left Panel: Orion's State Visualizer -->
        <div class="w-full md:w-1/4 bg-gray-900 rounded-2xl shadow-lg p-6 flex flex-col items-center justify-start">
             <h2 class="text-xl font-bold text-white mb-4">Orion's State</h2>
            <div id="stateVisualizerContainer" class="w-full h-64 md:h-auto md:flex-grow bg-gray-800/50 rounded-lg">
                <canvas id="stateVisualizer" class="w-full h-full"></canvas>
            </div>
        </div>

        <!-- Center Panel: Main Application -->
        <div class="w-full md:w-1/2 bg-gray-900 rounded-2xl shadow-lg p-6 md:p-8 space-y-6 flex flex-col">
            <div class="text-center">
                <h1 class="text-3xl font-bold text-white">Voice AI Assistant</h1>
                <p id="status" class="text-gray-400 mt-2">Press and hold the button to speak</p>
            </div>

            <div class="flex justify-center items-center py-8 relative">
                <button id="recordButton" class="bg-red-600 hover:bg-red-700 text-white rounded-full w-24 h-24 flex items-center justify-center transition-transform transform focus:outline-none focus:ring-4 focus:ring-red-500/50">
                    <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" x2="12" y1="19" y2="22"></line></svg>
                </button>
                <button id="interruptButton" class="hidden absolute bg-gray-600 hover:bg-gray-700 text-white rounded-full w-16 h-16 flex items-center justify-center transition-opacity focus:outline-none focus:ring-4 focus:ring-gray-500/50">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="6" y="6" width="12" height="12"></rect></svg>
                </button>
            </div>
            
            <div id="visualizerContainer" class="w-full h-24 bg-gray-800/50 rounded-lg">
                <canvas id="visualizer" class="w-full h-full"></canvas>
            </div>

            <div class="flex-grow flex flex-col">
                <div id="conversation" class="space-y-4 flex-grow max-h-96 overflow-y-auto p-4 bg-gray-800/50 rounded-lg">
                    <!-- Conversation will be appended here -->
                </div>
                <div class="flex justify-end gap-2 mt-2">
                    <button id="copyButton" class="text-xs text-gray-400 hover:text-white">Copy</button>
                    <button id="clearButton" class="text-xs text-gray-400 hover:text-white">Clear</button>
                </div>
            </div>
        </div>

        <!-- Right Panel: Settings -->
        <div class="w-full md:w-1/4 bg-gray-900 rounded-2xl shadow-lg p-6 space-y-4">
            <h2 class="text-xl font-bold text-white text-center">Settings</h2>

            <div class="space-y-2">
                <label for="instructions" class="text-sm font-medium text-gray-400">Instructions (Orion's Persona)</label>
                <textarea id="instructions" rows="4" class="w-full bg-gray-700 text-white rounded-lg p-2 focus:outline-none focus:ring-2 focus:ring-red-500 text-sm">You are Orion, a helpful and friendly AI assistant. Do not mention that you are an LLM or AI model. Keep your responses concise and conversational.</textarea>
            </div>
            
            <div class="space-y-2">
                <label for="contextControl" class="flex justify-between text-sm font-medium text-gray-400">
                    <span>Context Length</span>
                    <span id="contextValue">10</span>
                </label>
                <input id="contextControl" type="range" min="2" max="20" value="10" step="2" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
            </div>
            
            <div class="space-y-2">
                <label for="tempControl" class="flex justify-between text-sm font-medium text-gray-400">
                    <span>Model Temp</span>
                    <span id="tempValue">0.7</span>
                </label>
                <input id="tempControl" type="range" min="0.1" max="1.0" value="0.7" step="0.1" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
            </div>

            <div class="space-y-2">
                <label for="speedControl" class="flex justify-between text-sm font-medium text-gray-400">
                    <span>Speech Speed</span>
                    <span id="speedValue">0.13</span>
                </label>
                <input id="speedControl" type="range" min="0.97" max="1.2" value="1.0" step="0.01" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
            </div>

             <div class="space-y-2">
                <label for="styleControl" class="text-sm font-medium text-gray-400">Speech Visualizer Style</label>
                <select id="styleControl" class="w-full bg-gray-700 text-white rounded-lg p-2 focus:outline-none focus:ring-2 focus:ring-red-500">
                    <option value="bars">Frequency Bars</option>
                    <option value="waveform">Waveform</option>
                </select>
            </div>
             <div class="space-y-2">
                <label for="colorControl" class="text-sm font-medium text-gray-400">Color Scheme</label>
                <select id="colorControl" class="w-full bg-gray-700 text-white rounded-lg p-2 focus:outline-none focus:ring-2 focus:ring-red-500">
                    <option value="orion">Orion Blue</option>
                    <option value="retro">Retro Green</option>
                    <option value="vaporwave">Vaporwave</option>
                </select>
            </div>
        </div>
    </div>

    <script>
        // --- Element References ---
        const recordButton = document.getElementById('recordButton');
        const interruptButton = document.getElementById('interruptButton');
        const statusDiv = document.getElementById('status');
        const conversationDiv = document.getElementById('conversation');
        const speedControl = document.getElementById('speedControl');
        const speedValue = document.getElementById('speedValue');
        const tempControl = document.getElementById('tempControl');
        const tempValue = document.getElementById('tempValue');
        const styleControl = document.getElementById('styleControl');
        const colorControl = document.getElementById('colorControl');
        const visualizerCanvas = document.getElementById('visualizer');
        const canvasCtx = visualizerCanvas.getContext('2d');
        const visualizerContainer = document.getElementById('visualizerContainer');
        const stateVisualizerCanvas = document.getElementById('stateVisualizer');
        const stateCtx = stateVisualizerCanvas.getContext('2d');
        const stateVisualizerContainer = document.getElementById('stateVisualizerContainer');
        const contextControl = document.getElementById('contextControl');
        const contextValue = document.getElementById('contextValue');
        const instructionsText = document.getElementById('instructions');
        const clearButton = document.getElementById('clearButton');
        const copyButton = document.getElementById('copyButton');

        // --- State Management ---
        let socket;
        let mediaRecorder;
        let audioChunks = [];
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let currentAudioSource = null;
        let analyser;
        let animationFrameId;
        let audioQueue = [];
        let isPlayingAudio = false;
        let orionState = 'idle';
        let liveMicAnalyser; 
        let liveMicSource;

        // --- Event Listeners ---
        tempControl.addEventListener('input', () => { tempValue.textContent = parseFloat(tempControl.value).toFixed(1); });
        contextControl.addEventListener('input', () => { contextValue.textContent = contextControl.value; });
        speedControl.addEventListener('input', () => {
            const actualSpeed = parseFloat(speedControl.value);
            const minSpeed = 0.97; const maxSpeed = 1.2;
            const normalizedValue = (actualSpeed - minSpeed) / (maxSpeed - minSpeed);
            speedValue.textContent = normalizedValue.toFixed(2);
            if(currentAudioSource) currentAudioSource.playbackRate.value = actualSpeed;
        });
        clearButton.addEventListener('click', () => { 
            conversationDiv.innerHTML = '';
            // Future enhancement: send a message to the server to clear its history as well.
        });
        copyButton.addEventListener('click', () => {
             const conversationText = conversationDiv.innerText;
             const textArea = document.createElement("textarea");
             textArea.value = conversationText;
             document.body.appendChild(textArea);
             textArea.select();
             document.execCommand("copy");
             textArea.remove();
             updateStatus('Conversation copied!');
             setTimeout(() => updateStatusBasedOnState(), 2000);
        });
        interruptButton.addEventListener('click', () => {
            if (currentAudioSource) currentAudioSource.stop();
            audioQueue = [];
            isPlayingAudio = false;
            updateStatus('Ready. Press the button to speak.');
            interruptButton.classList.add('hidden');
        });


        // --- Core Functions ---
        function updateStatus(newStatus) {
            statusDiv.textContent = newStatus;
            const oldState = orionState;
            if (newStatus.startsWith('Recording')) orionState = 'listening';
            else if (newStatus.startsWith('Processing')) orionState = 'processing';
            else if (newStatus.startsWith('Playing')) orionState = 'speaking';
            else orionState = 'idle';

            if (orionState === 'processing' && oldState !== 'processing') {
                createParticles(true); // Create more particles for busy state
            } else if (oldState === 'processing' && orionState !== 'processing') {
                createParticles(false); // Reset to normal particle count
            }
        }
        function updateStatusBasedOnState() {
             if (orionState === 'idle') updateStatus('Ready. Press the button to speak.');
             else if (orionState === 'speaking') updateStatus('Playing response...');
        }

        function setupWebSocket() { 
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws`;
            socket = new WebSocket(wsUrl);
            socket.onopen = () => {  updateStatus('Connection established. Hold button to speak.'); };
            socket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.transcript) appendMessage('You', data.transcript);
                else if (data.llm_response) appendMessage('Assistant', data.llm_response);
                else if (data.audio_response) {
                    audioQueue.push(data.audio_response);
                    processAudioQueue();
                }
                else if (data.error) {
                    const errorMessage = `Error: ${data.error}`;
                    updateStatus(errorMessage);
                    appendMessage('System', errorMessage, 'text-red-400');
                    setTimeout(() => updateStatus('Ready. Press the button to speak.'), 3000);
                }
            };
            socket.onclose = () => { updateStatus('Connection lost. Please refresh.'); };
        } 
        function processAudioQueue() { 
            if (isPlayingAudio || audioQueue.length === 0) return;
            isPlayingAudio = true;
            const base64String = audioQueue.shift();
            playAudio(base64String);
        }
        async function playAudio(base64String) {
            try {
                if (currentAudioSource) currentAudioSource.stop();
                cancelAnimationFrame(animationFrameId);
                const binaryString = window.atob(base64String);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) bytes[i] = binaryString.charCodeAt(i);
                
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                analyser.connect(audioContext.destination);
                source.playbackRate.value = parseFloat(speedControl.value);
                source.start(0);
                currentAudioSource = source;
                updateStatus('Playing response...');
                interruptButton.classList.remove('hidden');
                drawVisualizer();
                source.onended = () => {
                    currentAudioSource = null;
                    cancelAnimationFrame(animationFrameId);
                    canvasCtx.clearRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
                    isPlayingAudio = false;
                    processAudioQueue();
                     if (audioQueue.length === 0) {
                        updateStatus('Ready. Press the button to speak.');
                        interruptButton.classList.add('hidden');
                    }
                };
            } catch (error) {
                console.error("Failed to play audio:", error);
                updateStatus('Error playing audio response.');
                isPlayingAudio = false;
            }
        }
        function drawVisualizer() { 
            animationFrameId = requestAnimationFrame(drawVisualizer);
            const selectedStyle = styleControl.value;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            canvasCtx.fillStyle = 'rgb(31, 41, 55)';
            canvasCtx.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
            if (selectedStyle === 'bars') {
                analyser.getByteFrequencyData(dataArray);
                drawBars(dataArray, bufferLength);
            } else if (selectedStyle === 'waveform') {
                analyser.getByteTimeDomainData(dataArray);
                drawWaveform(dataArray, bufferLength);
            }
        } 
        function drawBars(dataArray, bufferLength) {
            const barWidth = (visualizerCanvas.width / bufferLength) * 1.5; let x = 0; const colorScheme = colorControl.value;
            for (let i = 0; i < bufferLength; i++) {
                const barHeight = dataArray[i] / 2; let r, g, b;
                if (colorScheme === 'orion') { r = barHeight + 50 * (i/bufferLength); g = 100 * (i/bufferLength); b = 150; } 
                else if (colorScheme === 'retro') { r = 50; g = barHeight + 100 * (i/bufferLength); b = 50; } 
                else { r = 150 * (i/bufferLength); g = barHeight; b = 200; }
                canvasCtx.fillStyle = `rgb(${r},${g},${b})`;
                canvasCtx.fillRect(x, visualizerCanvas.height - barHeight, barWidth, barHeight);
                x += barWidth + 1;
            }
        }
        function drawWaveform(dataArray, bufferLength) {
            canvasCtx.lineWidth = 2; const colorScheme = colorControl.value;
            if (colorScheme === 'orion') canvasCtx.strokeStyle = 'rgb(147, 197, 253)';
            else if (colorScheme === 'retro') canvasCtx.strokeStyle = 'rgb(74, 222, 128)';
            else canvasCtx.strokeStyle = 'rgb(244, 114, 182)';
            canvasCtx.beginPath();
            const currentPlaybackRate = currentAudioSource ? currentAudioSource.playbackRate.value : 1.0;
            const sliceWidth = (visualizerCanvas.width * 1.0 / bufferLength) * currentPlaybackRate;
            let x = 0;
            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0; const y = v * visualizerCanvas.height / 2;
                if (i === 0) canvasCtx.moveTo(x, y);
                else canvasCtx.lineTo(x, y);
                x += sliceWidth;
            }
            canvasCtx.lineTo(Math.min(x, visualizerCanvas.width), visualizerCanvas.height / 2);
            canvasCtx.stroke();
        }
        function appendMessage(sender, text) { 
            const senderClass = sender === 'You' ? 'font-semibold text-blue-300' : 'font-semibold text-green-300';
            const messageElement = document.createElement('div');
            messageElement.innerHTML = `<p class="${senderClass}">${sender}</p><p class="text-white">${text}</p>`;
            conversationDiv.appendChild(messageElement);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
        } 
        
        async function startRecording() {
            interruptButton.click(); 
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                liveMicSource = audioContext.createMediaStreamSource(stream);
                liveMicAnalyser = audioContext.createAnalyser();
                liveMicAnalyser.fftSize = 256;
                liveMicSource.connect(liveMicAnalyser);

                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) audioChunks.push(event.data);
                };
                mediaRecorder.onstop = async () => {
                    if (socket && socket.readyState === WebSocket.OPEN && audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
                        const reader = new FileReader();
                        reader.readAsDataURL(audioBlob); 
                        reader.onloadend = () => {
                            const payload = {
                                audio: reader.result.split(',')[1],
                                temperature: parseFloat(tempControl.value),
                                context_length: parseInt(contextControl.value),
                                instructions: instructionsText.value
                            };
                            socket.send(JSON.stringify(payload));
                        }
                    }
                    stream.getTracks().forEach(track => track.stop());
                    if(liveMicSource) liveMicSource.disconnect();
                    liveMicSource = null;
                };
                audioChunks = [];
                mediaRecorder.start();
                updateStatus('Recording... Release to stop.');
                recordButton.classList.add('pulse');
            } catch (err) {
                console.error('Error accessing microphone:', err);
                updateStatus('Error: Microphone access denied.');
            }
        }

        function stopRecording() { 
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                updateStatus('Processing...');
                recordButton.classList.remove('pulse');
            }
        }
        function setAllCanvasSizes() {
            visualizerCanvas.width = visualizerContainer.clientWidth;
            visualizerCanvas.height = visualizerContainer.clientHeight;
            stateVisualizerCanvas.width = stateVisualizerContainer.clientWidth;
            stateVisualizerCanvas.height = stateVisualizerContainer.clientHeight;
        }

        let particles = [];
        const baseParticleCount = 150;
        function createParticles(isBusy = false) {
             particles = [];
            const particleCount = isBusy ? 250 : baseParticleCount;
            for (let i = 0; i < particleCount; i++) {
                particles.push({
                    x: Math.random() * stateVisualizerCanvas.width,
                    y: Math.random() * stateVisualizerCanvas.height,
                    radius: Math.random() * 1.5 + 1,
                    vx: (Math.random() - 0.5) * 0.4,
                    vy: (Math.random() - 0.5) * 0.4,
                    baseVx: (Math.random() - 0.5) * 0.4,
                    baseVy: (Math.random() - 0.5) * 0.4,
                    color: `rgba(147, 197, 253, ${Math.random() * 0.5 + 0.3})`
                });
            }
        }
        function drawOrionState() {
             stateCtx.clearRect(0, 0, stateVisualizerCanvas.width, stateVisualizerCanvas.height);
            let avgVolume = 0;
            let analyserToUse = null;

            if (orionState === 'speaking' && analyser) analyserToUse = analyser;
            else if (orionState === 'listening' && liveMicAnalyser) analyserToUse = liveMicAnalyser;
            
            if (analyserToUse) {
                const dataArray = new Uint8Array(analyserToUse.frequencyBinCount);
                analyserToUse.getByteFrequencyData(dataArray);
                avgVolume = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
            }
            
            particles.forEach((p, index) => {
                let modulation = 1.0;
                if (orionState === 'processing') {
                    p.vx += (Math.random() - 0.5) * 0.8; p.vy += (Math.random() - 0.5) * 0.8;
                    if (Math.random() > 0.95) p.color = `rgba(${Math.random()*255}, ${Math.random()*255}, ${Math.random()*255}, 0.9)`;
                } else if (orionState === 'speaking' || orionState === 'listening') {
                    modulation = 1 + (avgVolume / 128);
                    p.vx = p.baseVx * modulation; p.vy = p.baseVy * modulation;
                    p.color = `rgba(147, 197, 253, ${Math.min(0.8, 0.3 + avgVolume / 256)})`;
                } else { // Idle
                     p.vx = p.baseVx; p.vy = p.baseVy;
                     p.color = `rgba(147, 197, 253, 0.6)`;
                }
                p.x += p.vx; p.y += p.vy;
                if (p.x < 0 || p.x > stateVisualizerCanvas.width) p.vx *= -1;
                if (p.y < 0 || p.y > stateVisualizerCanvas.height) p.vy *= -1;
                stateCtx.beginPath();
                stateCtx.arc(p.x, p.y, p.radius, 0, Math.PI * 2);
                stateCtx.fillStyle = p.color;
                stateCtx.fill();
                if (orionState === 'processing') {
                    for (let i = index + 1; i < particles.length; i++) {
                        const other = particles[i];
                        const dist = Math.hypot(p.x - other.x, p.y - other.y);
                        if (dist < 60) {
                            stateCtx.beginPath(); stateCtx.moveTo(p.x, p.y);
                            stateCtx.lineTo(other.x, other.y);
                            stateCtx.strokeStyle = `rgba(255, 255, 255, ${0.6 - dist/100})`;
                            stateCtx.stroke();
                        }
                    }
                }
            });
            requestAnimationFrame(drawOrionState);
        }
        
        // --- Final Setup ---
        recordButton.addEventListener('mousedown', startRecording);
        recordButton.addEventListener('mouseup', stopRecording);
        recordButton.addEventListener('touchstart', (e) => { e.preventDefault(); startRecording(); });
        recordButton.addEventListener('touchend', stopRecording);
        window.addEventListener('load', () => {
            setupWebSocket(); setAllCanvasSizes();
            if (stateVisualizerCanvas.width > 0) { createParticles(); drawOrionState(); }
        });
        window.addEventListener('resize', setAllCanvasSizes);
    </script>
</body>
</html>

